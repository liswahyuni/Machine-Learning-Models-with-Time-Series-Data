# -*- coding: utf-8 -*-
"""Lis_Wahyuni_Proyek_2_Time_Series_LSTM_(1) vR1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16EuZ0DicIf3RDzQTHcSFC6VNMTA3UkHg

Nama: Lis Wahyuni

Download dataset from Kaggle
"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle

!cp /content/kaggle.json ~/.kaggle/

# Permission for the json to act
!chmod 600 ~/.kaggle/kaggle.json

# List all datasets in Kaggle
!kaggle datasets list

!kaggle datasets download -d budincsevity/szeged-weather

!ls

!unzip szeged-weather.zip

import pandas as pd

df = pd.read_csv('weatherHistory.csv')
df

df = df.drop(columns=['Loud Cover', 'Daily Summary'], axis=1)

df.info()

df.isnull().sum()

df['Precip Type'].value_counts()

df_new = df.dropna()

df_new.info()

print(f"Old dataframe shape: {df.shape}")
print(f"New dataframe shape: {df_new.shape}")

import numpy as np
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import tensorflow as tf
import seaborn as sns

# I choose only "Formatted Date" and "Temperature (C)" as input
df_new = df_new.drop(columns=['Summary', 'Precip Type', 'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Pressure (millibars)'], axis=1)
df_new

df_new["Formatted Date"] = pd.to_datetime(df_new["Formatted Date"], utc=True)

dates = df_new['Formatted Date'].values
temp  = df_new['Temperature (C)'].values

df_new["Formatted Date"]

df_new.info()

import matplotlib as mpl
mpl.rcParams['agg.path.chunksize'] = 10000

plt.figure(figsize=(15,5))
plt.plot(dates, temp)
plt.title('Temperature (C)', fontsize=20);

# split data jadi training-testing
from sklearn.model_selection import train_test_split
dates_train, dates_test, temp_train, temp_test = train_test_split(dates, temp, test_size=0.2, shuffle=False)

dates_train

import matplotlib as mpl
mpl.rcParams['agg.path.chunksize'] = 10000

plt.figure(figsize=(15,5))
plt.plot(dates_train, temp_train)
plt.title('Temperature (C)', fontsize=20);

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

from tensorflow import keras
from keras import regularizers
from keras.regularizers import l2

train_set = windowed_dataset(temp_train, window_size=24, batch_size=100, shuffle_buffer=1000)
test_set = windowed_dataset(temp_test, window_size=24, batch_size=100, shuffle_buffer=1000)
model = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(16, return_sequences=True, kernel_regularizer=l2(0.1), bias_regularizer=l2(0.1)),
  tf.keras.layers.LSTM(16),
  tf.keras.layers.Dense(8, activation="relu"),
  tf.keras.layers.Dropout(0.15),
  tf.keras.layers.Dense(4, activation='sigmoid'),
  tf.keras.layers.Dense(1)
])

optimizer = tf.keras.optimizers.Adam(lr=0.0001)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

max = df['Temperature (C)'].max()
min = df['Temperature (C)'].min()
mae_skala_data = 0.1*(max-min)

print("Max Value Temp: ", max)
print("Min Value Temp: ", min)
print("Mae: ", mae_skala_data)

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if((logs.get('mae')<mae_skala_data and logs.get('val_mae')<mae_skala_data)):
      print("\nMAE dan Validasi MAE telah kurang dari 10% skala data.")
      self.model.stop_training = True
callbacks = myCallback()

history = model.fit(train_set, epochs=200, validation_data=(test_set), verbose=2, callbacks=[callbacks])

import matplotlib.pyplot as plt

plt.figure(figsize=[10,8])
plt.plot(history.history['loss'], 'black', linewidth=2.0)
plt.plot(history.history['val_loss'], 'red', linewidth=2.0)
plt.legend(['Training Loss', 'Validation Loss'], fontsize=14, loc='best')
plt.title('Loss Curves', fontsize=12)
plt.ylabel('Loss', fontsize=10)
plt.xlabel('Epochs', fontsize=10)
plt.show()

plt.figure(figsize=[10,8])
plt.plot(history.history['mae'], 'blue', linewidth=2.0)
plt.plot(history.history['val_mae'], 'orange', linewidth=2.0)
plt.legend(['Training MAE', 'Validation MAE'], fontsize=14, loc='best')
plt.title('Accuracy Curves', fontsize=12)
plt.ylabel('Accuracy', fontsize=10)
plt.xlabel('Epochs', fontsize=10)
plt.show()

